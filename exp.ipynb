{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e7dbec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_nltk(base_path=r\"C:\\nltk_data\"):\n",
    "    \"\"\"\n",
    "    Ensures NLTK is fully set up with all required resources.\n",
    "    Works across environments and Python versions (including 3.13).\n",
    "    \"\"\"\n",
    "    import os, nltk\n",
    "    \n",
    "    # 1️⃣ Create directory if missing\n",
    "    os.makedirs(base_path, exist_ok=True)\n",
    "    \n",
    "    # 2️⃣ Set data path\n",
    "    nltk.data.path = [base_path]\n",
    "    \n",
    "    # 3️⃣ Required resources\n",
    "    required_packages = [\"punkt\", \"punkt_tab\", \"stopwords\"]\n",
    "    \n",
    "    # 4️⃣ Download missing ones\n",
    "    for pkg in required_packages:\n",
    "        try:\n",
    "            nltk.data.find(pkg)\n",
    "        except LookupError:\n",
    "            nltk.download(pkg, download_dir=base_path)\n",
    "    \n",
    "    print(\"✅ NLTK setup complete. Path:\", nltk.data.path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1644f0e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ NLTK setup complete. Path: ['C:\\\\nltk_data']\n",
      "Filtered: ['NLTK', 'setup', 'function', 'test', 'successful', '!']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to C:\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "setup_nltk()  # Run once per environment\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "text = \"NLTK setup function test successful!\"\n",
    "tokens = word_tokenize(text)\n",
    "filtered = [w for w in tokens if w.lower() not in stopwords.words('english')]\n",
    "\n",
    "print(\"Filtered:\", filtered)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4e2f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hello, World!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac403ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install numpy\n",
    "# !pip install pandas\n",
    "# !pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5b7c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9f76a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import numpy as np        # For numerical operations\n",
    "import pandas as pd       # For data manipulation and analysis\n",
    "import matplotlib.pyplot as plt  # For data visualization\n",
    "%matplotlib inline\n",
    "\n",
    "# Importing WordCloud for text visualization\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Importing NLTK for natural language processing\n",
    "import nltk\n",
    "from nltk.corpus import stopwords    # For stopwords\n",
    "\n",
    "\n",
    "# Downloading NLTK data\n",
    "# nltk.download('stopwords')   # Downloading stopwords data\n",
    "# nltk.download('punkt')       # Downloading tokenizer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66265318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the CSV file\n",
    "df = pd.read_csv('spam.csv')\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04b56e3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns = ['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06885592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target                                               text\n",
       "0    ham  Go until jurong point, crazy.. Available only ...\n",
       "1    ham                      Ok lar... Joking wif u oni...\n",
       "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3    ham  U dun say so early hor... U c already then say...\n",
       "4    ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename the columns name\n",
    "df.rename(columns = {'v1': 'target', 'v2': 'text'}, inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "816d685d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd7d7dd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                               text\n",
       "0       0  Go until jurong point, crazy.. Available only ...\n",
       "1       0                      Ok lar... Joking wif u oni...\n",
       "2       1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3       0  U dun say so early hor... U c already then say...\n",
       "4       0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data Processing\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "df['target'] = encoder.fit_transform(df['target'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a30718e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(403)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check duplicate values\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e97b00f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5572"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "984466fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5169"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove Duplicate\n",
    "df = df.drop_duplicates(keep = 'first')\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4907a736",
   "metadata": {},
   "source": [
    "Feature Engg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6294b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "\n",
    "# # Define download path explicitly (this avoids hidden folder issues)\n",
    "# nltk.download('punkt', download_dir='nltk_data')\n",
    "# nltk.download('stopwords', download_dir='nltk_data')\n",
    "\n",
    "# # Add this path manually so NLTK can find it\n",
    "# nltk.data.path.append('nltk_data')\n",
    "\n",
    "# print(\"✅ punkt and stopwords downloaded successfully and path added\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fec082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# from nltk.corpus import stopwords\n",
    "# from nltk.stem import PorterStemmer\n",
    "\n",
    "# ps = PorterStemmer()\n",
    "\n",
    "# text = \"Go until Jurong Point, crazy!! Available only in Bugis n Great World la e buffet...\"\n",
    "# tokens = nltk.word_tokenize(text)\n",
    "\n",
    "# print(tokens[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a246456c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d2b294",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3be642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1300aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# from nltk.corpus import stopwords\n",
    "# from nltk.stem.porter import PorterStemmer\n",
    "# import string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2175de0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Porter Stemmer for text stemming\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "# Importing the string module for handling special characters\n",
    "import string\n",
    "\n",
    "# Creating an instance of the Porter Stemmer\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18ab7eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Lowercase transformation and text preprocessing function\n",
    "def transform_text(text):\n",
    "    # Transform the text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Tokenization using NLTK\n",
    "    text = nltk.word_tokenize(text)\n",
    "    \n",
    "    # Removing special characters\n",
    "    y = []\n",
    "    for i in text:\n",
    "        if i.isalnum():\n",
    "            y.append(i)\n",
    "            \n",
    "    # Removing stop words and punctuation\n",
    "    text = y[:]\n",
    "    y.clear()\n",
    "    \n",
    "    # Loop through the tokens and remove stopwords and punctuation\n",
    "    for i in text:\n",
    "        if i not in stopwords.words('english') and i not in string.punctuation:\n",
    "            y.append(i)\n",
    "        \n",
    "    # Stemming using Porter Stemmer\n",
    "    text = y[:]\n",
    "    y.clear()\n",
    "    for i in text:\n",
    "        y.append(ps.stem(i))\n",
    "    \n",
    "    # Join the processed tokens back into a single string\n",
    "    return \" \".join(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9137378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go jurong point crazi avail bugi n great world la e buffet cine got amor wat\n"
     ]
    }
   ],
   "source": [
    "sample_text = \"Go until Jurong Point, crazy!! Available only in Bugis n Great World la e buffet... Cine there got Amore wat...\"\n",
    "print(transform_text(sample_text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3f1224b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>transformed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>go jurong point crazi avail bugi n great world...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ok lar joke wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entri 2 wkli comp win fa cup final tkt 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>u dun say earli hor u c alreadi say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah think goe usf live around though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                               text  \\\n",
       "0       0  Go until jurong point, crazy.. Available only ...   \n",
       "1       0                      Ok lar... Joking wif u oni...   \n",
       "2       1  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3       0  U dun say so early hor... U c already then say...   \n",
       "4       0  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                    transformed_text  \n",
       "0  go jurong point crazi avail bugi n great world...  \n",
       "1                              ok lar joke wif u oni  \n",
       "2  free entri 2 wkli comp win fa cup final tkt 21...  \n",
       "3                u dun say earli hor u c alreadi say  \n",
       "4               nah think goe usf live around though  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['transformed_text'] = df['text'].apply(transform_text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9a9f7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "tfid = TfidfVectorizer(max_features = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3fd2b6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tfid.fit_transform(df['transformed_text']).toarray()\n",
    "y = df['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49facfcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "160023a8",
   "metadata": {},
   "source": [
    "Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60fed972",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test , y_train, y_test = train_test_split(X,y,test_size = 0.20, random_state = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa0b813",
   "metadata": {},
   "source": [
    "Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6bb85713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting xgboost\n",
      "  Downloading xgboost-3.1.1-py3-none-win_amd64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from xgboost) (2.3.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from xgboost) (1.16.3)\n",
      "Downloading xgboost-3.1.1-py3-none-win_amd64.whl (72.0 MB)\n",
      "   ---------------------------------------- 0.0/72.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.5/72.0 MB 3.5 MB/s eta 0:00:21\n",
      "    --------------------------------------- 1.0/72.0 MB 2.7 MB/s eta 0:00:26\n",
      "   - -------------------------------------- 1.8/72.0 MB 3.2 MB/s eta 0:00:22\n",
      "   - -------------------------------------- 2.6/72.0 MB 3.3 MB/s eta 0:00:21\n",
      "   - -------------------------------------- 3.4/72.0 MB 3.5 MB/s eta 0:00:20\n",
      "   -- ------------------------------------- 4.5/72.0 MB 3.6 MB/s eta 0:00:19\n",
      "   -- ------------------------------------- 5.2/72.0 MB 3.6 MB/s eta 0:00:19\n",
      "   --- ------------------------------------ 6.0/72.0 MB 3.7 MB/s eta 0:00:18\n",
      "   --- ------------------------------------ 6.8/72.0 MB 3.7 MB/s eta 0:00:18\n",
      "   ---- ----------------------------------- 7.3/72.0 MB 3.6 MB/s eta 0:00:18\n",
      "   ---- ----------------------------------- 8.1/72.0 MB 3.6 MB/s eta 0:00:18\n",
      "   ---- ----------------------------------- 8.9/72.0 MB 3.6 MB/s eta 0:00:18\n",
      "   ----- ---------------------------------- 9.7/72.0 MB 3.6 MB/s eta 0:00:18\n",
      "   ----- ---------------------------------- 10.2/72.0 MB 3.6 MB/s eta 0:00:18\n",
      "   ----- ---------------------------------- 10.7/72.0 MB 3.5 MB/s eta 0:00:18\n",
      "   ------ --------------------------------- 11.3/72.0 MB 3.5 MB/s eta 0:00:18\n",
      "   ------ --------------------------------- 12.1/72.0 MB 3.3 MB/s eta 0:00:18\n",
      "   ------ --------------------------------- 12.6/72.0 MB 3.3 MB/s eta 0:00:18\n",
      "   ------- -------------------------------- 13.1/72.0 MB 3.3 MB/s eta 0:00:19\n",
      "   ------- -------------------------------- 13.9/72.0 MB 3.3 MB/s eta 0:00:18\n",
      "   -------- ------------------------------- 14.4/72.0 MB 3.3 MB/s eta 0:00:18\n",
      "   -------- ------------------------------- 14.7/72.0 MB 3.2 MB/s eta 0:00:18\n",
      "   -------- ------------------------------- 14.9/72.0 MB 3.1 MB/s eta 0:00:19\n",
      "   -------- ------------------------------- 15.5/72.0 MB 3.0 MB/s eta 0:00:19\n",
      "   -------- ------------------------------- 16.0/72.0 MB 3.0 MB/s eta 0:00:19\n",
      "   --------- ------------------------------ 16.5/72.0 MB 3.0 MB/s eta 0:00:19\n",
      "   --------- ------------------------------ 17.0/72.0 MB 3.0 MB/s eta 0:00:19\n",
      "   --------- ------------------------------ 17.6/72.0 MB 3.0 MB/s eta 0:00:19\n",
      "   ---------- ----------------------------- 18.1/72.0 MB 2.9 MB/s eta 0:00:19\n",
      "   ---------- ----------------------------- 18.6/72.0 MB 2.9 MB/s eta 0:00:19\n",
      "   ---------- ----------------------------- 19.4/72.0 MB 2.9 MB/s eta 0:00:19\n",
      "   ----------- ---------------------------- 19.9/72.0 MB 2.9 MB/s eta 0:00:18\n",
      "   ----------- ---------------------------- 20.4/72.0 MB 2.9 MB/s eta 0:00:18\n",
      "   ----------- ---------------------------- 21.0/72.0 MB 2.9 MB/s eta 0:00:18\n",
      "   ----------- ---------------------------- 21.5/72.0 MB 2.9 MB/s eta 0:00:18\n",
      "   ------------ --------------------------- 22.3/72.0 MB 2.9 MB/s eta 0:00:18\n",
      "   ------------ --------------------------- 23.1/72.0 MB 2.9 MB/s eta 0:00:17\n",
      "   ------------ --------------------------- 23.3/72.0 MB 2.9 MB/s eta 0:00:17\n",
      "   ------------- -------------------------- 23.9/72.0 MB 2.9 MB/s eta 0:00:17\n",
      "   ------------- -------------------------- 24.6/72.0 MB 2.9 MB/s eta 0:00:17\n",
      "   ------------- -------------------------- 25.2/72.0 MB 2.9 MB/s eta 0:00:17\n",
      "   -------------- ------------------------- 25.7/72.0 MB 2.9 MB/s eta 0:00:17\n",
      "   -------------- ------------------------- 26.5/72.0 MB 2.9 MB/s eta 0:00:16\n",
      "   --------------- ------------------------ 27.0/72.0 MB 2.9 MB/s eta 0:00:16\n",
      "   --------------- ------------------------ 27.5/72.0 MB 2.9 MB/s eta 0:00:16\n",
      "   --------------- ------------------------ 28.3/72.0 MB 2.9 MB/s eta 0:00:16\n",
      "   ---------------- ----------------------- 28.8/72.0 MB 2.9 MB/s eta 0:00:16\n",
      "   ---------------- ----------------------- 29.1/72.0 MB 2.9 MB/s eta 0:00:16\n",
      "   ---------------- ----------------------- 29.4/72.0 MB 2.8 MB/s eta 0:00:16\n",
      "   ---------------- ----------------------- 29.6/72.0 MB 2.8 MB/s eta 0:00:16\n",
      "   ---------------- ----------------------- 29.9/72.0 MB 2.8 MB/s eta 0:00:16\n",
      "   ---------------- ----------------------- 30.4/72.0 MB 2.8 MB/s eta 0:00:16\n",
      "   ----------------- ---------------------- 31.2/72.0 MB 2.8 MB/s eta 0:00:15\n",
      "   ----------------- ---------------------- 31.5/72.0 MB 2.8 MB/s eta 0:00:15\n",
      "   ----------------- ---------------------- 32.2/72.0 MB 2.8 MB/s eta 0:00:15\n",
      "   ------------------ --------------------- 32.8/72.0 MB 2.7 MB/s eta 0:00:15\n",
      "   ------------------ --------------------- 33.3/72.0 MB 2.7 MB/s eta 0:00:15\n",
      "   ------------------ --------------------- 33.8/72.0 MB 2.7 MB/s eta 0:00:14\n",
      "   ------------------- -------------------- 34.3/72.0 MB 2.7 MB/s eta 0:00:14\n",
      "   ------------------- -------------------- 34.9/72.0 MB 2.7 MB/s eta 0:00:14\n",
      "   ------------------- -------------------- 35.7/72.0 MB 2.7 MB/s eta 0:00:14\n",
      "   -------------------- ------------------- 36.2/72.0 MB 2.7 MB/s eta 0:00:14\n",
      "   -------------------- ------------------- 37.0/72.0 MB 2.8 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 37.5/72.0 MB 2.8 MB/s eta 0:00:13\n",
      "   --------------------- ------------------ 38.0/72.0 MB 2.8 MB/s eta 0:00:13\n",
      "   --------------------- ------------------ 38.8/72.0 MB 2.8 MB/s eta 0:00:13\n",
      "   --------------------- ------------------ 39.1/72.0 MB 2.8 MB/s eta 0:00:12\n",
      "   --------------------- ------------------ 39.6/72.0 MB 2.7 MB/s eta 0:00:12\n",
      "   --------------------- ------------------ 39.6/72.0 MB 2.7 MB/s eta 0:00:12\n",
      "   ---------------------- ----------------- 40.1/72.0 MB 2.7 MB/s eta 0:00:12\n",
      "   ---------------------- ----------------- 40.4/72.0 MB 2.7 MB/s eta 0:00:12\n",
      "   ---------------------- ----------------- 40.6/72.0 MB 2.7 MB/s eta 0:00:12\n",
      "   ---------------------- ----------------- 41.2/72.0 MB 2.6 MB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 41.9/72.0 MB 2.7 MB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 42.5/72.0 MB 2.7 MB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 43.0/72.0 MB 2.7 MB/s eta 0:00:11\n",
      "   ------------------------ --------------- 43.5/72.0 MB 2.7 MB/s eta 0:00:11\n",
      "   ------------------------ --------------- 43.8/72.0 MB 2.7 MB/s eta 0:00:11\n",
      "   ------------------------ --------------- 44.3/72.0 MB 2.6 MB/s eta 0:00:11\n",
      "   ------------------------ --------------- 44.8/72.0 MB 2.6 MB/s eta 0:00:11\n",
      "   ------------------------- -------------- 45.4/72.0 MB 2.6 MB/s eta 0:00:11\n",
      "   ------------------------- -------------- 45.9/72.0 MB 2.6 MB/s eta 0:00:10\n",
      "   ------------------------- -------------- 46.4/72.0 MB 2.6 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 46.9/72.0 MB 2.6 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 47.4/72.0 MB 2.6 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 48.2/72.0 MB 2.6 MB/s eta 0:00:10\n",
      "   --------------------------- ------------ 48.8/72.0 MB 2.6 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 49.5/72.0 MB 2.6 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 50.1/72.0 MB 2.6 MB/s eta 0:00:09\n",
      "   ---------------------------- ----------- 50.6/72.0 MB 2.6 MB/s eta 0:00:09\n",
      "   ---------------------------- ----------- 51.4/72.0 MB 2.6 MB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 52.2/72.0 MB 2.7 MB/s eta 0:00:08\n",
      "   ----------------------------- ---------- 52.7/72.0 MB 2.7 MB/s eta 0:00:08\n",
      "   ----------------------------- ---------- 53.2/72.0 MB 2.7 MB/s eta 0:00:08\n",
      "   ----------------------------- ---------- 53.7/72.0 MB 2.7 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 54.3/72.0 MB 2.7 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 55.1/72.0 MB 2.7 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 55.6/72.0 MB 2.7 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 56.1/72.0 MB 2.7 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 56.6/72.0 MB 2.7 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 57.4/72.0 MB 2.7 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 58.2/72.0 MB 2.7 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 58.5/72.0 MB 2.7 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 59.2/72.0 MB 2.7 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 59.8/72.0 MB 2.7 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 60.6/72.0 MB 2.7 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 61.3/72.0 MB 2.7 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 61.9/72.0 MB 2.7 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 62.7/72.0 MB 2.7 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 63.4/72.0 MB 2.7 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 64.0/72.0 MB 2.7 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 64.7/72.0 MB 2.7 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 65.3/72.0 MB 2.7 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 65.8/72.0 MB 2.7 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 66.6/72.0 MB 2.7 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 67.1/72.0 MB 2.7 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 67.6/72.0 MB 2.7 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 68.4/72.0 MB 2.7 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 68.9/72.0 MB 2.7 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 69.5/72.0 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  70.3/72.0 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  70.8/72.0 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  71.3/72.0 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  71.8/72.0 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  71.8/72.0 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 72.0/72.0 MB 2.7 MB/s  0:00:26\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-3.1.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\Admin\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c4533178",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9a61fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(kernel= \"sigmoid\", gamma  = 1.0)\n",
    "knc = KNeighborsClassifier()\n",
    "mnb = MultinomialNB()\n",
    "dtc = DecisionTreeClassifier(max_depth = 5)\n",
    "lrc = LogisticRegression(solver = 'liblinear', penalty = 'l1')\n",
    "rfc = RandomForestClassifier(n_estimators = 50, random_state = 2 )\n",
    "abc = AdaBoostClassifier(n_estimators = 50, random_state = 2)\n",
    "bc = BaggingClassifier(n_estimators = 50, random_state = 2)\n",
    "etc = ExtraTreesClassifier(n_estimators = 50, random_state = 2)\n",
    "gbdt = GradientBoostingClassifier(n_estimators = 50, random_state = 2)    \n",
    "xgb  = XGBClassifier(n_estimators = 50, random_state = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "35c27125",
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = {\n",
    "    'SVC': svc,\n",
    "    'KNN': knc,\n",
    "    'NB': mnb,\n",
    "    'DT': dtc,\n",
    "    'LR': lrc,\n",
    "    'RF': rfc,\n",
    "    'Adaboost': abc,\n",
    "    'Bgc': bc,\n",
    "    'ETC': etc,\n",
    "    'GBDT': gbdt,\n",
    "    'xgb': xgb\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02e5a80",
   "metadata": {},
   "source": [
    "Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5fd2ffba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "def train_classifier(clfs, X_train, y_train, X_test, y_test):\n",
    "    clfs.fit(X_train,y_train)\n",
    "    y_pred = clfs.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    return accuracy , precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7819697d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For:  SVC\n",
      "Accuracy:  0.9671179883945842\n",
      "Precision:  0.9333333333333333\n",
      "\n",
      "For:  KNN\n",
      "Accuracy:  0.9274661508704062\n",
      "Precision:  1.0\n",
      "\n",
      "For:  NB\n",
      "Accuracy:  0.9709864603481625\n",
      "Precision:  0.9655172413793104\n",
      "\n",
      "For:  DT\n",
      "Accuracy:  0.9361702127659575\n",
      "Precision:  0.9\n",
      "\n",
      "For:  LR\n",
      "Accuracy:  0.9632495164410058\n",
      "Precision:  0.9629629629629629\n",
      "\n",
      "For:  RF\n",
      "Accuracy:  0.9700193423597679\n",
      "Precision:  0.9421487603305785\n",
      "\n",
      "For:  Adaboost\n",
      "Accuracy:  0.9235976789168279\n",
      "Precision:  0.8734177215189873\n",
      "\n",
      "For:  Bgc\n",
      "Accuracy:  0.9622823984526112\n",
      "Precision:  0.9024390243902439\n",
      "\n",
      "For:  ETC\n",
      "Accuracy:  0.9709864603481625\n",
      "Precision:  0.921875\n",
      "\n",
      "For:  GBDT\n",
      "Accuracy:  0.9497098646034816\n",
      "Precision:  0.93\n",
      "\n",
      "For:  xgb\n",
      "Accuracy:  0.9690522243713733\n",
      "Precision:  0.9568965517241379\n"
     ]
    }
   ],
   "source": [
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "for name , clfs in clfs.items():\n",
    "    current_accuracy, current_precision = train_classifier(clfs, X_train, y_train, X_test, y_test)\n",
    "    print()\n",
    "    print(\"For: \", name)\n",
    "    print(\"Accuracy: \", current_accuracy)\n",
    "    print(\"Precision: \", current_precision)\n",
    "    \n",
    "    accuracy_scores.append(current_accuracy)\n",
    "    precision_scores.append(current_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1bbce3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
